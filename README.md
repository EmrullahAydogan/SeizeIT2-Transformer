# SeizeIT2: Transformer-Based Seizure Detection

ğŸ§  **Unsupervised anomaly detection for epileptic seizure identification using Transformer-Autoencoder architecture**

## ğŸ“‹ Overview

This is a pilot study implementing a Transformer-based autoencoder for real-time epilepsy seizure detection using multi-modal physiological signals (EEG, ECG, EMG, Movement).

**Key Features:**
- âœ… Unsupervised learning approach (learns from normal data only)
- âœ… Multi-modal signal fusion (16-channel EEG + ECG + EMG + MOV)
- âœ… Transformer architecture with self-attention mechanism
- âœ… Academic-grade evaluation (ROC, AUC, sensitivity, specificity)
- âœ… Per-patient performance analysis

## ğŸ¯ Dataset

**Source:** SeizeIT2 Dataset (125 patients with focal epilepsy)

**Selected Patients (n=3):**
| Patient | Duration (h) | Seizures | Vigilance | Seizure Type |
|---------|-------------|----------|-----------|--------------|
| sub-015 | 20.9 | 9 | Mixed | Tonic |
| sub-022 | 21.5 | 7 | Mixed | Automatisms |
| sub-103 | 18.4 | 15 | Mixed | Hyperkinetic |
| **Total** | **60.8** | **31** | - | - |

Selection criteria:
- Duration > 18 hours (circadian rhythm coverage)
- Mixed vigilance states (both sleep and wake seizures)
- Multiple seizure types (diversity)
- Multi-modal sensor availability

## ğŸ—ï¸ Architecture

**Model:** Transformer-Autoencoder
- Input: 16 channels Ã— 1000 timesteps (4 seconds @ 250 Hz)
- Embedding: 1D-CNN (64 filters, kernel=5)
- Attention: 4 heads, 64 dimensions
- Decoder: 1D-CNN reconstruction
- Loss: Mean Squared Error (MSE)

**Training:**
- Optimizer: Adam (lr=1e-4)
- Epochs: 5 (baseline, will be extended to 50-100)
- Batch size: 16
- Hardware: RTX 4070 8GB

## ğŸ“Š Results

*Results will be updated after running `evaluate_per_patient.m`*

**Preliminary Performance (per-patient):**
- AUC: TBD
- Sensitivity: TBD
- Specificity: TBD
- F1-Score: TBD

## ğŸš€ Usage

### Prerequisites
```matlab
% MATLAB R2020b+ with:
% - Deep Learning Toolbox
% - Signal Processing Toolbox
% - Statistics and Machine Learning Toolbox
```

### Quick Start

```matlab
% 1. Data Preprocessing (requires SeizeIT2 dataset)
run('MatlabProject/process_final_dataset.m');

% 2. Create Training Data
run('MatlabProject/create_model_data.m');

% 3. Train Model
run('MatlabProject/train_transformer_autoencoder.m');

% 4. Evaluate (Academic Analysis)
run('MatlabProject/evaluate_per_patient.m');

% 5. Visualize Explainability
run('MatlabProject/visualize_explainability.m');
```

## ğŸ“ Project Structure

```
SeizeIT2/
â”œâ”€â”€ MatlabProject/
â”‚   â”œâ”€â”€ train_transformer_autoencoder.m  # Model training
â”‚   â”œâ”€â”€ evaluate_per_patient.m           # Academic evaluation â­ NEW
â”‚   â”œâ”€â”€ process_final_dataset.m          # Data preprocessing
â”‚   â”œâ”€â”€ create_model_data.m              # Windowing & splitting
â”‚   â”œâ”€â”€ visualize_explainability.m       # Attention visualization
â”‚   â”œâ”€â”€ compare_normal_vs_seizure.m      # Baseline comparison
â”‚   â”œâ”€â”€ generate_academic_matrix.m       # Patient selection analysis
â”‚   â”œâ”€â”€ ModelData/
â”‚   â”‚   â”œâ”€â”€ Trained_Transformer_Final.mat
â”‚   â”‚   â”œâ”€â”€ Train/*.mat                  # Training windows
â”‚   â”‚   â””â”€â”€ Test/*.mat                   # Test windows
â”‚   â”œâ”€â”€ ProcessedData/*.mat              # Preprocessed signals
â”‚   â””â”€â”€ Results/                         # Evaluation outputs
â”‚       â”œâ”€â”€ ROC_Curves_PerPatient.png
â”‚       â”œâ”€â”€ Confusion_Matrices.png
â”‚       â””â”€â”€ PerPatient_Performance.csv
â””â”€â”€ dataset/                             # SeizeIT2 raw data (not included)
```

## âš ï¸ Limitations

**Hardware Constraints:**
- GPU Memory: 8GB limits cohort size to 3 patients
- Future work: Cloud-based scaling (AWS/GCP)

**Statistical:**
- Small sample size (n=3) â†’ This is a **pilot study**
- No cross-validation yet (planned: LOPO-CV)

**Clinical:**
- No real-time latency analysis
- No prospective validation
- Requires clinician review before deployment

## ğŸ”® Future Work

**Short-term:**
- [ ] Leave-One-Patient-Out Cross-Validation
- [ ] Extended training (50-100 epochs)
- [ ] Threshold optimization per-patient
- [ ] Ablation study (window sizes, modalities)

**Long-term:**
- [ ] Scale to 10-15 patients (cloud GPU)
- [ ] Real-time inference pipeline
- [ ] Attention weight visualization
- [ ] Clinical validation study

## ğŸ“š Citation

*Paper in preparation*

```bibtex
@misc{seizeit2_transformer2025,
  title={Transformer-Based Anomaly Detection for Epileptic Seizure Identification: A Pilot Study},
  author={[Your Name]},
  year={2025},
  note={Code available at: https://github.com/[username]/SeizeIT2-Transformer}
}
```

## ğŸ“„ License

MIT License (or specify your preference)

## ğŸ™ Acknowledgments

- SeizeIT2 Dataset: [Original dataset authors]
- Hardware: RTX 4070 8GB

---

**Status:** ğŸŸ¡ In Development (Pilot Study Phase)

**Last Updated:** January 2025
